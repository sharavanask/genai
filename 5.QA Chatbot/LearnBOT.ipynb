{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BYfPKMfw7jR",
        "outputId": "7cea3ac2-e451-4985-f26f-70eab05663ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.24.13\n"
          ]
        }
      ],
      "source": [
        "pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz"
      ],
      "metadata": {
        "id": "Vje_zZp1w-xj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=fitz.open('resume1.pdf')\n",
        "s=[]\n",
        "for i in doc.pages():\n",
        "  for j in i.get_text().split('\\n'):\n",
        "    s.append(j)\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRLmhjJjxBbS",
        "outputId": "7d42a80c-7b4f-49c5-f5ac-f9a6cadcf915"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Department of AI & DS ',\n",
              " ' ',\n",
              " 'UNIT I ',\n",
              " ' FUNDAMENTALS OF DEEP LEARNING ',\n",
              " 'Syllabus: Introduction to Neural Network- Feed Forward Neural Nets -',\n",
              " 'Tensorflow -Deep Learning Fundamentals: Fundamental deep learning ',\n",
              " 'concepts, Deep learning algorithms, and their types ',\n",
              " 'INTRODUCTION TO NEURAL NETWORKS ',\n",
              " '• Artificial neural networks are popular machine learning techniques that ',\n",
              " 'simulate the mechanism of learning in biological organisms. ',\n",
              " '• The human nervous system contains cells, which are referred to as ',\n",
              " 'neurons.  ',\n",
              " '• The foundational unit of the human brain is the neuron. A tiny piece of ',\n",
              " 'the brain, about the size of grain of rice, contains over 10,000 neurons, ',\n",
              " 'each of which forms an average of 6,000 connections with other neuron ',\n",
              " '• The neurons are connected to one another with the use of axons and ',\n",
              " 'dendrites, and the connecting regions between axons and dendrites are ',\n",
              " 'referred to as synapses ',\n",
              " ' ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " '• The strengths of synaptic connections often change in response to external ',\n",
              " 'stimuli. This change is how learning takes place in living organisms. ',\n",
              " '• This biological mechanism is simulated in artificial neural networks, which ',\n",
              " 'contain computation units that are referred to as neurons. ',\n",
              " '• The computational units are connected to one another through weights, which ',\n",
              " 'serve the same role as the strengths of synaptic connections in biological ',\n",
              " 'organisms. ',\n",
              " '• After being weighted by the strength of their respective connections, the inputs ',\n",
              " 'are summed together in the cell body. This sum is then transformed into a new ',\n",
              " 'signal that’s propagated along the cell’s axon and sent off to other neurons. ',\n",
              " '• An artificial neural network computes a function of the inputs by propagating ',\n",
              " 'the computed values from the input neurons to the output neuron(s) and using ',\n",
              " 'the weights as intermediate parameters. ',\n",
              " '• Learning occurs by changing the weights connecting the neurons. Just as ',\n",
              " 'external stimuli are needed for learning in biological organisms, the external ',\n",
              " 'stimulus in artificial neural networks is provided by the training data ',\n",
              " 'containing examples of input-output pairs of the function to be learned. ',\n",
              " '•  For example, the training data might contain pixel representations of images ',\n",
              " '(input) and their annotated labels (e.g., carrot, banana) as the output. ',\n",
              " '• The training data provides feedback to the correctness of the weights in the ',\n",
              " 'neural network depending on how well the predicted output (e.g., probability ',\n",
              " 'of carrot) for a particular input matches the annotated output label in the ',\n",
              " 'training data ',\n",
              " '• The weights between neurons are adjusted in a neural network in response to ',\n",
              " 'prediction errors. ',\n",
              " '• This ability to accurately compute functions of unseen inputs by training over ',\n",
              " 'a finite set of input-output pairs is referred to as model generalization.  ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " '• The primary usefulness of all machine learning models is gained from their ',\n",
              " 'ability to generalize their learning from seen training data to unseen examples. ',\n",
              " '• A key advantage of neural networks over traditional machine learning is that ',\n",
              " 'the former provides a higher-level abstraction of expressing semantic insights ',\n",
              " 'about data domains by architectural design choices in the computational ',\n",
              " 'graph.  ',\n",
              " '• The second advantage is that neural networks provide a simple way to adjust ',\n",
              " 'the complexity of a model by adding or removing neurons from the ',\n",
              " 'architecture according to the availability of training data or computational ',\n",
              " 'power. ',\n",
              " '• In 1943 by Warren S. McCulloch and Walter H. Pitts., ',\n",
              " '•  Just as in biological neurons, our artificial neuron takes in some number of ',\n",
              " 'inputs, x1 , x2 ,. . . , xn , each of which is multiplied by a specific weight, w1 ',\n",
              " ',w2 , . . . ,wn .These weighted inputs are, as before, summed together to ',\n",
              " 'produce the logit of the neuron, ',\n",
              " '• In many cases, the logit also includes a bias, which is a constant . The logit is ',\n",
              " 'then passed through a function f to produce the output y = f(z) . This output ',\n",
              " 'can be transmitted to other neurons ',\n",
              " ' ',\n",
              " ' ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'FEED FORWARD NEURAL NETWORKS (FFNN) ',\n",
              " 'Feed Forward Neural Networks are foundational to the field of deep learning, ',\n",
              " 'providing a basic architecture for many advanced neural network structures. ',\n",
              " 'Understanding their workings, strengths, and limitations is crucial for developing ',\n",
              " 'and applying neural network-based solutions effectively. By leveraging various ',\n",
              " 'techniques and optimizations, FFNNs can be fine-tuned to perform a wide range ',\n",
              " 'of tasks, from simple classifications to complex predictions. ',\n",
              " 'Introduction to Neural Networks ',\n",
              " 'Neural Networks: Inspired by the human brain, neural networks are a series of ',\n",
              " 'algorithms that attempt to recognize underlying relationships in a set of data ',\n",
              " 'through a process that mimics the way the human brain operates. ',\n",
              " 'Feed Forward Neural Networks (FFNN): One of the simplest types of artificial ',\n",
              " 'neural networks where connections between nodes do not form a cycle. This is ',\n",
              " 'the fundamental structure for many other types of neural networks. ',\n",
              " 'Structure of FFNN ',\n",
              " 'Nodes/Neurons: The basic units of neural networks. Each neuron receives inputs, ',\n",
              " 'processes them, and passes on its output to the next layer. ',\n",
              " 'Layers: ',\n",
              " 'Input Layer: The layer that receives the initial data. ',\n",
              " 'Hidden Layers: Intermediate layers that perform computations and extract ',\n",
              " 'features. There can be multiple hidden layers. ',\n",
              " 'Output Layer: The final layer that provides the output of the network. ',\n",
              " 'Weights and Biases: Each connection between neurons has an associated weight, ',\n",
              " 'and each neuron has an associated bias. These parameters are adjusted during ',\n",
              " 'training. ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'How FFNN Works ',\n",
              " 'Initialization: Weights and biases are initialized, usually with small random ',\n",
              " 'values. ',\n",
              " 'Forward Propagation: ',\n",
              " 'Data flows from the input layer through the hidden layers to the output layer. ',\n",
              " 'Each neuron processes the input it receives by applying a weighted sum, adding ',\n",
              " 'a bias, and passing the result through an activation function. ',\n",
              " 'Forward propagation is the process through which inputs are passed through the ',\n",
              " \"network to generate an output. Here's a step-by-step breakdown: \",\n",
              " '1. Input Layer: ',\n",
              " 'o The network receives input data xxx. ',\n",
              " '2. Hidden Layers: ',\n",
              " 'o Each hidden layer consists of neurons, each performing a linear ',\n",
              " 'transformation followed by a non-linear activation function. ',\n",
              " 'o For the first hidden layer:  ',\n",
              " ' ',\n",
              " 'Repeat the above transformation for each subsequent layer ',\n",
              " '3. Output Layer: ',\n",
              " '• Perform a final linear transformation:  ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " ' ',\n",
              " 'Activation Functions: ',\n",
              " ' ',\n",
              " 'Loss Function: ',\n",
              " 'Measures the difference between the predicted output and the actual output. ',\n",
              " 'Common loss functions include Mean Squared Error (MSE) for regression tasks ',\n",
              " 'and Cross-Entropy Loss for classification tasks. ',\n",
              " 'Backpropagation: ',\n",
              " 'The process of updating the weights and biases based on the error calculated from ',\n",
              " 'the loss function. Backward propagation (backprop) is the process of updating the ',\n",
              " \"network's weights and biases based on the error of the output. The goal is to \",\n",
              " \"minimize the loss function by adjusting the parameters. Here's a step-by-step \",\n",
              " 'breakdown: ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Gradient Descent: An optimization algorithm used to minimize the loss function ',\n",
              " 'by adjusting weights in the direction of the negative gradient. ',\n",
              " 'Learning Rate: A hyperparameter that controls the size of the steps taken to ',\n",
              " 'reach a minimum of the loss function. ',\n",
              " 'Iterations/Epochs: The entire process of forward propagation and ',\n",
              " 'backpropagation is repeated for several iterations (epochs) until the network ',\n",
              " 'learns the patterns in the data. ',\n",
              " 'Applications of FFNN ',\n",
              " 'Classification: Image recognition, spam detection, sentiment analysis. ',\n",
              " 'Regression: Predicting continuous values like house prices, stock prices. ',\n",
              " 'Feature Extraction: As part of more complex models like Convolutional Neural ',\n",
              " 'Networks (CNNs) and Recurrent Neural Networks (RNNs). ',\n",
              " 'Advantages of FFNN ',\n",
              " 'Simplicity: Easy to implement and understand. ',\n",
              " 'Universality: Can approximate any continuous function given enough neurons ',\n",
              " 'and layers. ',\n",
              " 'Challenges and Limitations ',\n",
              " 'Overfitting: Can perform poorly on new data if it learns the noise in the training ',\n",
              " 'data. ',\n",
              " 'Computationally Intensive: Requires significant computational resources for ',\n",
              " 'large datasets and complex architectures. ',\n",
              " 'Vanishing/Exploding Gradients: During backpropagation, gradients can become ',\n",
              " 'too small or too large, making training difficult. ',\n",
              " 'Improving FFNN Performance ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Regularization: Techniques like L1 and L2 regularization to prevent overfitting. ',\n",
              " 'Dropout: Randomly dropping neurons during training to prevent overfitting. ',\n",
              " 'Batch Normalization: Normalizing inputs of each layer to improve convergence ',\n",
              " 'speed and stability. ',\n",
              " 'Advanced Optimizers: Using optimizers like Adam, RMSprop that adapt learning ',\n",
              " 'rates for faster convergence. ',\n",
              " 'PERCEPTRON ',\n",
              " 'A perceptron is a type of artificial neuron and the fundamental building block of ',\n",
              " 'artificial neural networks, inspired by the biological neural networks found in the ',\n",
              " 'human brain. Developed by Frank Rosenblatt, it is the simplest form of a neural ',\n",
              " 'network model used for binary classification tasks.  ',\n",
              " 'Structure of a Perceptron ',\n",
              " 'A perceptron consists of the following components: ',\n",
              " '1. Inputs These are the features of the input data. ',\n",
              " '2. Weights Each input has an associated weight that signifies its importance ',\n",
              " 'in the decision-making process. ',\n",
              " '3. Bias: This is an additional parameter used to adjust the output along with ',\n",
              " 'the weighted sum of the inputs. ',\n",
              " '4. Activation Function: This function processes the weighted sum of the ',\n",
              " 'inputs and the bias to produce the final output. ',\n",
              " ' ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Training a Perceptron ',\n",
              " 'The perceptron is trained using a supervised learning algorithm called the ',\n",
              " 'perceptron learning algorithm, which involves adjusting the weights and bias ',\n",
              " 'based on the errors in the predictions. The steps are as follows: ',\n",
              " '1. Initialize Weights and Bias: Start with random values for the weights ',\n",
              " 'and bias. ',\n",
              " \"2. Forward Pass: For each training example, compute the perceptron's \",\n",
              " 'output. ',\n",
              " '3. Error Calculation: Compare the predicted output to the actual label and ',\n",
              " 'calculate the error. ',\n",
              " '4. Weight and Bias Update: Adjust the weights and bias to minimize the ',\n",
              " 'error.  ',\n",
              " 'Limitations ',\n",
              " 'While perceptrons are foundational and useful for understanding neural networks, ',\n",
              " 'they have several limitations: ',\n",
              " '1. Linearity: Perceptrons can only solve linearly separable problems. They ',\n",
              " 'cannot handle problems where the classes cannot be separated by a single ',\n",
              " 'straight line. ',\n",
              " '2. Single Layer: A single-layer perceptron cannot model complex functions. ',\n",
              " 'To handle more complex problems, we need multi-layer perceptrons ',\n",
              " '(MLPs), which introduce hidden layers and more sophisticated activation ',\n",
              " 'functions. ',\n",
              " ' ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'TENSORFLOW ',\n",
              " 'An open-source machine learning framework developed by the Google Brain ',\n",
              " 'team. It is designed to simplify the development and deployment of machine ',\n",
              " 'learning models, particularly deep learning models. TensorFlow provides a ',\n",
              " 'comprehensive and flexible ecosystem for developing and deploying machine ',\n",
              " 'learning models. Its scalability, versatility, and production readiness make it an ',\n",
              " 'excellent choice for both research and industrial applications. By leveraging its ',\n",
              " 'powerful features and extensive community support, practitioners can build and ',\n",
              " 'deploy state-of-the-art machine learning solutions efficiently. ',\n",
              " 'Released in 2015, TensorFlow has become one of the most popular frameworks ',\n",
              " 'for building machine learning applications. ',\n",
              " 'Key Features of TensorFlow ',\n",
              " '• Scalability: Supports distributed computing, allowing for scalable training on ',\n",
              " 'multiple GPUs and across different machines. ',\n",
              " '• Versatility: Suitable for various machine learning tasks, including neural ',\n",
              " 'networks, image and speech recognition, and natural language processing. ',\n",
              " '• Flexibility: Provides high-level APIs like Keras for easy model building and ',\n",
              " 'low-level operations for advanced users who need fine-grained control. ',\n",
              " '• Production Ready: Designed to transition from research prototypes to ',\n",
              " 'production systems seamlessly. ',\n",
              " '• Community and Ecosystem: Strong community support, extensive ',\n",
              " 'documentation, and a wide array of pre-trained models and tools. ',\n",
              " 'TensorFlow Architecture ',\n",
              " 'Tensors: The primary data structure in TensorFlow, representing multi-',\n",
              " 'dimensional arrays. These are similar to NumPy arrays but optimized for ',\n",
              " 'TensorFlow operations. ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Graphs: TensorFlow operations are described in a computation graph, where ',\n",
              " 'nodes represent operations and edges represent tensors. ',\n",
              " 'Sessions: Execution of the computation graph occurs within a session (in ',\n",
              " 'TensorFlow 1.x; sessions are abstracted away in TensorFlow 2.x). ',\n",
              " 'Core Components ',\n",
              " 'Tensors and Operations: ',\n",
              " 'Tensors: Data containers that flow through the computational graph. ',\n",
              " 'Operations (Ops): Functions that manipulate tensors, such as addition, ',\n",
              " 'multiplication, or complex mathematical functions. ',\n",
              " 'Layers and Models: ',\n",
              " 'Layers: Building blocks for neural networks, such as Dense, Conv2D, and LSTM ',\n",
              " 'layers. ',\n",
              " 'Models: Sequential and Functional APIs to define complex model architectures. ',\n",
              " 'Keras API: ',\n",
              " 'A high-level API integrated with TensorFlow for rapid prototyping and easy ',\n",
              " 'model building. ',\n",
              " 'TensorFlow Hub: ',\n",
              " 'A repository of pre-trained models for transfer learning and other applications. ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " ' ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'DEEP LEARNING FUNDAMENTALS: FUNDAMENTAL CONCEPTS ',\n",
              " ' ',\n",
              " 'Deep learning has significantly advanced the field of artificial intelligence by ',\n",
              " 'enabling machines to learn and make decisions with high accuracy. ',\n",
              " 'Understanding its fundamental concepts is essential for leveraging its power in ',\n",
              " 'various applications, from academic research to industrial innovations. With ',\n",
              " 'continuous improvements in algorithms, computing power, and data availability, ',\n",
              " 'the potential for deep learning applications is vast and ever-expanding. ',\n",
              " 'A subset of machine learning that involves neural networks with many layers ',\n",
              " '(hence \"deep\"). It aims to model complex patterns in data by learning multiple ',\n",
              " 'levels of abstraction. ',\n",
              " \"History: Deep learning's concepts date back to the 1940s and 1950s with the \",\n",
              " 'development of artificial neural networks. However, it gained significant ',\n",
              " 'attention in the 2010s due to advances in computing power, algorithms, and ',\n",
              " 'availability of large datasets. ',\n",
              " 'Deep learning has significantly advanced the field of artificial intelligence by ',\n",
              " 'enabling machines to learn and make decisions with high accuracy. ',\n",
              " 'Understanding its fundamental concepts is essential for leveraging its power in ',\n",
              " 'various applications, from academic research to industrial innovations. With ',\n",
              " 'continuous improvements in algorithms, computing power, and data availability, ',\n",
              " 'the potential for deep learning applications is vast and ever-expanding. ',\n",
              " 'Neural Networks: ',\n",
              " 'Neurons: Basic units of a neural network that take inputs, apply weights, add a ',\n",
              " 'bias, and pass through an activation function to produce an output. ',\n",
              " 'Layers: ',\n",
              " 'Input Layer: Receives the initial data. ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Hidden Layers: Intermediate layers where computations are performed to extract ',\n",
              " 'features. ',\n",
              " 'Output Layer: Produces the final output. ',\n",
              " 'Activation Functions: ',\n",
              " 'Introduce non-linearity into the model, allowing it to learn complex patterns. ',\n",
              " ' ',\n",
              " 'Forward and Backward Propagation: ',\n",
              " 'Forward Propagation: The process of passing inputs through the network to get ',\n",
              " 'the output. ',\n",
              " 'Backward Propagation: The process of adjusting the weights and biases using the ',\n",
              " 'gradient of the loss function to minimize error. It involves: ',\n",
              " 'Gradient Descent: An optimization algorithm to update weights. ',\n",
              " \"Learning Rate: A hyperparameter that controls how much the model's weights are \",\n",
              " 'adjusted with respect to the loss gradient. ',\n",
              " 'Loss Functions: ',\n",
              " 'Measure the difference between the predicted output and the actual output. ',\n",
              " 'Common Loss Functions: ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Mean Squared Error (MSE): Used for regression tasks. ',\n",
              " 'Cross-Entropy Loss: Used for classification tasks. ',\n",
              " 'Optimization Algorithms: ',\n",
              " 'Gradient Descent: Adjusts weights iteratively to minimize the loss function. ',\n",
              " 'Variants: ',\n",
              " 'Stochastic Gradient Descent (SGD): Uses a single data point to calculate ',\n",
              " 'gradients. ',\n",
              " 'Mini-batch Gradient Descent: Uses a small batch of data points. ',\n",
              " 'Adam: Combines the advantages of two other extensions of stochastic gradient ',\n",
              " 'descent, namely Adaptive Gradient Algorithm (AdaGrad) and Root Mean Square ',\n",
              " 'Propagation (RMSProp). ',\n",
              " 'Regularization Techniques: ',\n",
              " 'Prevent overfitting by adding a penalty to the loss function. ',\n",
              " 'L1 Regularization: Adds the absolute value of weights. ',\n",
              " 'L2 Regularization: Adds the squared value of weights (also known as Ridge ',\n",
              " 'Regression). ',\n",
              " 'Dropout: Randomly drops neurons during training to prevent overfitting. ',\n",
              " 'Hyperparameters: ',\n",
              " 'Learning Rate: Controls the step size during gradient descent. ',\n",
              " 'Batch Size: Number of training examples used in one iteration. ',\n",
              " 'Number of Epochs: Number of complete passes through the training dataset. ',\n",
              " 'Network Architecture: Number of layers, number of neurons per layer. ',\n",
              " 'Model Evaluation: ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Training and Validation: Split the data into training and validation sets to monitor ',\n",
              " \"the model's performance. \",\n",
              " 'Metrics: Accuracy, precision, recall, F1-score, ROC-AUC. ',\n",
              " 'TYPES OF NEURAL NETWORKS ',\n",
              " 'Feedforward Neural Networks (FFNN): Basic type of neural network where ',\n",
              " 'connections do not form cycles. ',\n",
              " 'Convolutional Neural Networks (CNN): Specialized for processing grid-like ',\n",
              " 'data such as images. Uses convolutional layers to detect features. ',\n",
              " 'Recurrent Neural Networks (RNN): Suitable for sequential data like time series ',\n",
              " 'or text. Uses loops to retain information across inputs. ',\n",
              " 'Long Short-Term Memory (LSTM): A type of RNN designed to overcome the ',\n",
              " 'vanishing gradient problem, suitable for long-term dependencies. ',\n",
              " 'Generative Adversarial Networks (GANs): Consist of two networks (generator ',\n",
              " 'and discriminator) that compete against each other to generate realistic data. ',\n",
              " 'PRACTICAL APPLICATIONS OF DEEP LEARNING ',\n",
              " 'Computer Vision: Image classification, object detection, facial recognition. ',\n",
              " 'Natural Language Processing (NLP): Sentiment analysis, machine translation, ',\n",
              " 'text generation. ',\n",
              " 'Speech Recognition: Transcribing spoken words into text. ',\n",
              " 'Healthcare: Disease prediction, medical image analysis. ',\n",
              " 'Autonomous Systems: Self-driving cars, robotics. ',\n",
              " 'DEEP LEARNING ALGORITHMS AND THEIR TYPES ',\n",
              " 'Deep learning algorithms are computational models inspired by the structure and ',\n",
              " 'function of the human brain. They consist of multiple layers of interconnected ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'neurons (artificial neurons) that can learn to represent and process data with ',\n",
              " 'increasing levels of abstraction. Here, we discuss various types of deep learning ',\n",
              " 'algorithms and their applications. ',\n",
              " 'Deep learning algorithms have revolutionized the field of artificial intelligence, ',\n",
              " 'offering powerful tools for a wide range of applications. By understanding the ',\n",
              " 'structure, function, and use-cases of different types of deep learning algorithms, ',\n",
              " 'practitioners can select the most appropriate models for their specific tasks. As ',\n",
              " 'research and development continue, the capabilities and efficiency of these ',\n",
              " 'algorithms are expected to grow, further expanding their applicability and impact. ',\n",
              " 'TYPES OF DEEP LEARNING ALGORITHMS ',\n",
              " 'Convolutional Neural Networks (CNN): ',\n",
              " 'Structure: Includes convolutional layers, pooling layers, and fully connected ',\n",
              " 'layers. Convolutional layers apply filters to detect features, pooling layers reduce ',\n",
              " 'dimensionality. ',\n",
              " 'Function: Excellent for processing grid-like data such as images. ',\n",
              " 'Example Application: Image classification (e.g., identifying objects in photos), ',\n",
              " 'object detection (e.g., detecting faces in images). ',\n",
              " 'Recurrent Neural Networks (RNN): ',\n",
              " 'Structure: Contains loops allowing information to persist. Each neuron can pass ',\n",
              " 'information to its successor neuron in the next time step. ',\n",
              " 'Function: Suitable for sequential data or time-series data. ',\n",
              " 'Example Application: Language modeling, text generation, time-series ',\n",
              " 'forecasting. ',\n",
              " 'Long Short-Term Memory Networks (LSTM): ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Structure: A type of RNN designed to overcome the vanishing gradient problem. ',\n",
              " 'Comprises cells, input gates, output gates, and forget gates to maintain long-term ',\n",
              " 'dependencies. ',\n",
              " 'Function: Effective at capturing long-range dependencies in sequence data. ',\n",
              " 'Example Application: Speech recognition, machine translation. ',\n",
              " 'Gated Recurrent Units (GRU): ',\n",
              " 'Structure: Similar to LSTM but with a simplified architecture (fewer gates). ',\n",
              " 'Function: Also used for sequence modeling with fewer parameters than LSTM. ',\n",
              " 'Example Application: Time-series prediction, language modeling. ',\n",
              " 'Generative Adversarial Networks (GANs): ',\n",
              " 'Structure: Comprises two networks – a generator and a discriminator. The ',\n",
              " 'generator creates fake data, and the discriminator evaluates its authenticity. ',\n",
              " 'Function: Used for generating new data that resembles the training data. ',\n",
              " 'Example Application: Image generation, data augmentation. ',\n",
              " 'ADVANCED DEEP LEARNING ARCHITECTURES ',\n",
              " '1. Transformer Networks: ',\n",
              " 'Structure: Comprises encoder-decoder architecture, primarily using self-attention ',\n",
              " 'mechanisms. ',\n",
              " 'Function: Designed for handling sequential data with long-range dependencies ',\n",
              " 'more efficiently than RNNs. ',\n",
              " 'Example Application: Machine translation, text summarization, language ',\n",
              " 'modeling (e.g., BERT, GPT). ',\n",
              " '2. Capsule Networks (CapsNets): ',\n",
              " '',\n",
              " 'Department of AI & DS ',\n",
              " ' ',\n",
              " 'Structure: Includes capsules that are groups of neurons representing different ',\n",
              " 'properties of objects. ',\n",
              " 'Function: Aims to address the shortcomings of CNNs in handling spatial ',\n",
              " 'hierarchies. ',\n",
              " 'Example Application: Image recognition, pose estimation. ',\n",
              " '3. Attention Mechanisms: ',\n",
              " 'Structure: A technique used to improve the performance of neural networks by ',\n",
              " 'focusing on the important parts of the input. ',\n",
              " 'Function: Often used in combination with RNNs or Transformers. ',\n",
              " 'Example Application: Machine translation, image captioning. ',\n",
              " 'APPLICATIONS OF DEEP LEARNING ALGORITHMS ',\n",
              " '• Image and Video Analysis: Object detection, image segmentation, face ',\n",
              " 'recognition. ',\n",
              " '• Natural Language Processing (NLP): Sentiment analysis, language ',\n",
              " 'translation, text summarization. ',\n",
              " '• Speech Recognition: Transcribing spoken words into text, voice command ',\n",
              " 'systems. ',\n",
              " '• Healthcare: Disease diagnosis, medical image analysis, drug discovery. ',\n",
              " '• Autonomous Vehicles: Object detection, path planning, sensor data fusion. ',\n",
              " '• Finance: Fraud detection, algorithmic trading, risk management. ',\n",
              " '• Gaming: AI game playing, virtual reality enhancements. ',\n",
              " '• Recommendation ',\n",
              " 'Systems: ',\n",
              " 'Personalized ',\n",
              " 'content ',\n",
              " 'recommendation, ',\n",
              " 'collaborative filtering ',\n",
              " ' ',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu\n",
        "!pip install langchain\n",
        "!pip install transformers\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDqWqvwCxuA4",
        "outputId": "89ac9f85-b547-406c-8167-b8543b1353ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S96rSYdzT00",
        "outputId": "1c0075e9-c37b-4afb-81aa-0091101b605a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "LhaVVFqnzLOI"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vector_store=FAISS.from_texts(s,HuggingFaceEmbeddings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkAWA3gKyAjM",
        "outputId": "27c06ad1-b3c9-44ec-edeb-7e5ec64870c8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-100-5be1adc402c6>:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  vector_store=FAISS.from_texts(s,HuggingFaceEmbeddings())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriver=vector_store.as_retriever()\n"
      ],
      "metadata": {
        "id": "KHotxKUF0AYi"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(retriver.get_relevant_documents(\"skills\",k=10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eWz7ITk63Xv",
        "outputId": "6c823a61-b320-41a5-9133-8ae37592ef28"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={}, page_content='training. '), Document(metadata={}, page_content='model building. '), Document(metadata={}, page_content='recognition. '), Document(metadata={}, page_content='ability to generalize their learning from seen training data to unseen examples. ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6MP_P9u6_kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# pipe = pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     max_new_tokens=50,\n",
        "#     padding_side='left',\n",
        "#     truncation=True\n",
        "# )\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=250,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "gpt2_model = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=gpt2_model,\n",
        "    retriever=retriver,\n",
        "    chain_type=\"stuff\",\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "bTwtSxu_1c_B"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  query=input()\n",
        "  if query=='exit':\n",
        "    break\n",
        "  response = qa_chain(query)\n",
        "  print(response['result'],response['source_documents'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQLhuekbS643",
        "outputId": "8e40c226-73eb-4f82-f235-79dd2db4869b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is an ANN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "Neurons: Basic units of a neural network that take inputs, apply weights, add a \n",
            "\n",
            "Neural Networks: Inspired by the human brain, neural networks are a series of \n",
            "\n",
            "TYPES OF NEURAL NETWORKS \n",
            "\n",
            "Nodes/Neurons: The basic units of neural networks. Each neuron receives inputs, \n",
            "\n",
            "Question: what is an ANN\n",
            "Helpful Answer: \"A neural network is a network of neurons that are connected to each other by a number of neurons. Each neuron sends input into a network of neurons, and the network in turn is connected to each other. Each neuron's state (the input state) is determined by the number of neurons in the network, and is considered as a vector of neurons connected to each other by a number of neurons.\n",
            "\n",
            "What's the Difference Between Nodes and Neurons?\" Answer: When you say \"neurons,\" you mean \"one of the neural networks that's connected to all neurons in a neural network.\" Neurons are one of two basic units of a neural network. One unit is the basic unit of the human brain. The other unit is a neural network that sends input into a network of neurons, the way you would use a computer to send messages over the internet. The neural network is often referred to as the brain. In human terms, it is a whole brain. You can see the distinction between the two types of neural networks in this video.\n",
            "\n",
            "What are Neural Networks and Does It Actually Work? Question: Is there any difference between neural networks and neurons? Answer: \"Nano networks\" are the most common [Document(metadata={}, page_content='Neurons: Basic units of a neural network that take inputs, apply weights, add a '), Document(metadata={}, page_content='Neural Networks: Inspired by the human brain, neural networks are a series of '), Document(metadata={}, page_content='TYPES OF NEURAL NETWORKS '), Document(metadata={}, page_content='Nodes/Neurons: The basic units of neural networks. Each neuron receives inputs, ')]\n",
            "Convolution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "Convolutional Neural Networks (CNN): \n",
            "\n",
            "TensorFlow operations. \n",
            "\n",
            "4. Activation Function: This function processes the weighted sum of the \n",
            "\n",
            "multiplication, or complex mathematical functions. \n",
            "\n",
            "Question: Convolution\n",
            "Helpful Answer: \n",
            "\n",
            "When you see one word, choose it from one sentence, or use the above method of choosing one word to answer a question.\n",
            "\n",
            "5. The Results:\n",
            "\n",
            "Now that you know how to calculate the probabilities of the various outcomes, let's move onto the actual training data. Let's take a look at the training data for the entire task.\n",
            "\n",
            "TensorFlow operations:\n",
            "\n",
            "Convolutional Neural Networks (CNN):\n",
            "\n",
            "Intermediate training training: \n",
            "\n",
            "1. 1st training:\n",
            "\n",
            "1st training, divided into 2 groups.\n",
            "\n",
            "2. 2nd training:\n",
            "\n",
            "2nd training, divided into 2 groups.\n",
            "\n",
            "2nd training, divided into 2 groups.\n",
            "\n",
            "3. 2nd training:\n",
            "\n",
            "2nd training, divided into 2 groups.\n",
            "\n",
            "3rd training:\n",
            "\n",
            "3rd training, divided into 2 groups.\n",
            "\n",
            "4. 2nd training:\n",
            "\n",
            "2nd training, divided into 2 groups.\n",
            "\n",
            "4th training:\n",
            "\n",
            "2nd training, divided into 2 groups.\n",
            "\n",
            "5. 2nd training:\n",
            "\n",
            "2nd training, divided into 2 groups.\n",
            "\n",
            "6. 2nd training:\n",
            " [Document(metadata={}, page_content='Convolutional Neural Networks (CNN): '), Document(metadata={}, page_content='TensorFlow operations. '), Document(metadata={}, page_content='4. Activation Function: This function processes the weighted sum of the '), Document(metadata={}, page_content='multiplication, or complex mathematical functions. ')]\n",
            "feedforward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "FEED FORWARD NEURAL NETWORKS (FFNN) \n",
            "\n",
            "Feedforward Neural Networks (FFNN): Basic type of neural network where \n",
            "\n",
            "Feed Forward Neural Networks are foundational to the field of deep learning, \n",
            "\n",
            "Forward Propagation: \n",
            "\n",
            "Question: feedforward\n",
            "Helpful Answer: \n",
            "\n",
            "Question: feedforward\n",
            "\n",
            "Feedforward Networks: Basic type of network where the neural information about a subject changes with time as we move on.\n",
            "\n",
            "For example, you can build feedforward networks based on the question:\n",
            "\n",
            "Q: How do you make a simple model that describes the distribution of food choices based on an arbitrary value?\n",
            "\n",
            "A: feedforward\n",
            "\n",
            "Q: I would like to add some additional information about the model I'm describing. I'm going to do the following:\n",
            "\n",
            "Q: What kind of food-choice system is the feedforward network that you built?\n",
            "\n",
            "A: Feedforward\n",
            "\n",
            "Q: Why did you decide to build this feedforward network?\n",
            "\n",
            "A: Feedforward\n",
            "\n",
            "Q: I see that your model is very simple. Can you do any more?\n",
            "\n",
            "A: No, but that's where the question comes in. When you choose the system, you get more information about how it looks, but you get less information about what you could be doing. The reason why I chose a feedforward is to show you the information that you could be doing.\n",
            "\n",
            "Q: I know that this system is pretty simple. I'm not quite [Document(metadata={}, page_content='FEED FORWARD NEURAL NETWORKS (FFNN) '), Document(metadata={}, page_content='Feedforward Neural Networks (FFNN): Basic type of neural network where '), Document(metadata={}, page_content='Feed Forward Neural Networks are foundational to the field of deep learning, '), Document(metadata={}, page_content='Forward Propagation: ')]\n",
            "exit\n"
          ]
        }
      ]
    }
  ]
}